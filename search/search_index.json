{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udc7e Code Interpreter API","text":"<p>CodeInterpreterAPI allows you to easily build apps like the \"Advanced Data Analysis\" you may know from ChatGPT. Build on top of LangChain and CodeBox, it provides a simple API for chatting with an AI that can run Python code to do anything you want.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Dataset Analysis, Stock Charting, Image Manipulation, ....</li> <li>Internet access and auto Python package installation</li> <li>Input <code>text + files</code> -&gt; Receive <code>text + files</code></li> <li>Conversation Memory: respond based on previous inputs</li> <li>Run everything local except the OpenAI API (OpenOrca or others maybe soon)</li> <li>Use CodeBox API for easy scaling in production</li> </ul>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Blog Post</li> <li>Github Repo</li> <li>Documentation</li> <li>Join the Discord</li> </ul>"},{"location":"bitcoin_chart/","title":"Bitcoin Chart","text":"<p>This example creates a CodeInterpreterSession and generates a response to plot the bitcoin chart for year 2023:</p> <pre><code>from codeinterpreterapi import CodeInterpreterSession\n\nwith CodeInterpreterSession() as session:\n  response = session.generate_response(\"Plot the bitcoin chart for year 2023\")\n\nprint(response.content)\nresponse.files[0].show_image() # Show the chart image\n</code></pre> <p>The session handles executing the python code to generate the chart in the sandboxed environment. The response contains the chart image that can be displayed.</p> <p> Bitcoin Chart Output</p>"},{"location":"code_interpreter_response/","title":"CodeInterpreterResponse","text":"<p>The CodeInterpreterResponse contains the AI agent's response.</p> <p>It contains:</p> <ul> <li><code>content</code>: text response content</li> <li><code>files</code>: list of generated File attachments</li> <li><code>code_log</code>: log of executed code snippets</li> </ul>"},{"location":"code_interpreter_session/","title":"CodeInterpreterSession","text":"<p>The CodeInterpreterSession is the main class that manages a conversational session between the user and AI agent. It handles starting, stopping and checking status of the secure isolated code execution environment.</p> <p>Key responsibilities:</p> <ul> <li>Starting and stopping the compute session</li> <li>Sending user input and files to the agent</li> <li>Running code in the compute container</li> <li>Retrieving output files and images</li> <li>Managing the chat history</li> <li>Logging</li> </ul> <p>It provides methods like:</p> <ul> <li><code>generate_response()</code>: Generate AI response for user input</li> <li><code>start() / stop()</code>: Start and stop the session</li> <li><code>log()</code>: Log messages</li> <li><code>show_code</code> - Callback to print code before running.</li> </ul> <p>The response generation happens through a pipeline:</p> <ol> <li>User input is parsed</li> <li>Code is executed if needed</li> <li>Files are processed if needed</li> <li>Final response is formatted and returned</li> </ol> <p>The <code>generate_response()</code> method handles this entire pipeline.</p> <p>Usage:</p> <pre><code>from codeinterpreterapi import CodeInterpreterSession\n\nwith CodeInterpreterSession() as session:\n  response = session.generate_response(\"Plot a histogram of the data\")\nprint(response.content) # print AI response\n</code></pre>"},{"location":"codebox/","title":"CodeBox","text":"<p>The CodeBox class provides the isolated secure environment for executing python code. It is used by the CodeInterpreterSession internally.</p> <p>It provides methods like:</p> <ul> <li><code>upload() / download()</code>: Upload and download files</li> <li><code>run()</code>: Run python code</li> <li><code>install()</code>: Install python packages</li> </ul> <p>The CodeBox handles setting up the environment, installing packages, running code, capturing output and making it available.</p> <p>It uses Docker containers under the hood to provide the isolated env.</p> <p>Usage:</p> <pre><code>from codeboxapi import CodeBox\n\ncodebox = CodeBox()\ncodebox.upload(\"data.csv\", b\"1,2,3\\\n4,5,6\")\noutput = codebox.run(\"import pandas as pd; df = pd.read_csv('data.csv')\")\nprint(output.content)\n</code></pre>"},{"location":"concepts_overview/","title":"Concepts Overview","text":"name description CodeInterpreterSession Main class that manages a code execution session CodeBox Handles code execution in a sandboxed environment File Represents a file for upload/download to CodeBox UserRequest User input message with optional file attachments CodeInterpreterResponse AI response message with optional files and code log"},{"location":"deploy/","title":"Deployment","text":"<p>CodeInterpreterAPI can be easily deployed to production using the CodeBox framework.</p>"},{"location":"deploy/#prerequisites","title":"Prerequisites","text":"<ul> <li>CodeBox API key</li> <li>Get your API key from CodeBox (you get an email with the api-key)</li> <li>CodeInterpreterAPI installed</li> <li><code>pip install codeinterpreterapi</code></li> </ul>"},{"location":"deploy/#setup","title":"Setup","text":"<p>Set the <code>CODEBOX_API_KEY</code> environment variable or directly in your code:</p> <pre><code>from codeinterpreterapi import settings\n\nsettings.CODEBOX_API_KEY = \"sk-...\"\n</code></pre>"},{"location":"deploy/#stopping-the-session","title":"Stopping the Session","text":"<p>Don't forget to stop the session when finished:</p> <pre><code>session.stop()\n</code></pre> <p>This will shutdown the CodeBox instance.</p>"},{"location":"deploy/#next-steps","title":"Next Steps","text":"<ul> <li>See the CodeBox docs for more details on deployment options.</li> <li>Look at the examples for more usage ideas.</li> <li>Contact Shroominic for assistance with deployment.</li> </ul>"},{"location":"file/","title":"File Object","text":"<p>The File class is used to represent files that are uploaded or downloaded during the session.</p> <p>It stores the filename and binary content of the file.</p> <p>It provides utility methods like:</p> <ul> <li><code>from_path()</code>: Create File from filesystem path</li> <li><code>from_url</code> - Create File from URL</li> <li><code>save()</code>: Save File to filesystem path</li> <li><code>show_image()</code>: Display image File</li> </ul> <p>Usage:</p> <pre><code>from codeinterpreterapi import File\n\nfile = File.from_path(\"image.png\")\nfile.show_image() # display image\nfile.save(\"copy.png\") # save copy\n</code></pre> <p>File objects can be passed to <code>CodeInterpreterSession.generate_response</code> to make them available to the agent.</p>"},{"location":"installation/","title":"Installation","text":"<p>Install the package:</p> <pre><code>pip install \"codeinterpreterapi[all]\"\n</code></pre> <p>Everything for local experiments are installed with the all extra. For deployments, you can use <code>pip install codeinterpreterapi</code> instead which does not install the additional dependencies.</p>"},{"location":"installation/#set-up-environment-variables","title":"Set Up Environment Variables","text":"<p>You will also need to configure API keys for the AI model you want to use, either OpenAI, Anthropic, or Azure.</p> <p>For OpenAI, create a <code>.env</code> file with:</p> <pre><code>OPENAI_API_KEY=sk-**********\n</code></pre> <p>or export as an environment variable in your terminal before running your code:</p> <pre><code>export OPENAI_API_KEY=sk-**********\n</code></pre> <p>For Azure, use:</p> <pre><code>OPENAI_API_TYPE=azure\nOPENAI_API_VERSION=2023-07-01-preview\nOPENAI_API_BASE=\nDEPLOYMENT_NAME=\n</code></pre>"},{"location":"iris_dataset/","title":"Analyzing the Iris Dataset","text":"<pre><code>from codeinterpreterapi import CodeInterpreterSession, File\n\nasync def main():\n    # context manager for auto start/stop of the session\n    async with CodeInterpreterSession() as session:\n        # define the user request\n        user_request = \"Analyze this dataset and plot something interesting about it.\"\n        files = [\n            File.from_path(\"examples/assets/iris.csv\"),\n        ]\n\n        # generate the response\n        response = await session.generate_response(\n            user_request, files=files\n        )\n\n        # output to the user\n        print(\"AI: \", response.content)\n        for file in response.files:\n            file.show_image()\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n</code></pre> <p> Iris Dataset Analysis Output</p>"},{"location":"settings/","title":"Settings","text":""},{"location":"settings/#settings-class-overview","title":"Settings Class Overview","text":"<p>The configuration is defined in a class named <code>CodeInterpreterAPISettings</code>, which inherits from Pydantic's <code>BaseSettings</code> class.</p> <p><code>codeinterpreterapi/config.py</code></p> <pre><code>class CodeInterpreterAPISettings(BaseSettings):\n...\n</code></pre>"},{"location":"settings/#setting-descriptions","title":"Setting Descriptions","text":""},{"location":"settings/#debug-settings","title":"Debug Settings","text":"<ul> <li><code>DEBUG: bool = False</code> Enables or disables the debug mode.</li> </ul>"},{"location":"settings/#api-keys","title":"API Keys","text":"<ul> <li> <p><code>OPENAI_API_KEY: Optional[str] = None</code> API key for the OpenAI service.</p> </li> <li> <p><code>AZURE_API_KEY: Optional[str] = None</code> API key for the Azure service.</p> </li> <li> <p><code>AZURE_API_BASE: Optional[str] = None</code> Base URL for Azure API.</p> </li> <li> <p><code>AZURE_API_VERSION: Optional[str] = None</code> API version for Azure service.</p> </li> <li> <p><code>AZURE_DEPLOYMENT_NAME: Optional[str] = None</code> Deployment name for Azure service.</p> </li> <li> <p><code>ANTHROPIC_API_KEY: Optional[SecretStr] = None</code> API key for the Anthropic service, stored securely.</p> </li> </ul>"},{"location":"settings/#llm-settings","title":"LLM Settings","text":"<ul> <li> <p><code>MODEL: str = \"gpt-3.5-turbo\"</code> The language model to be used.</p> </li> <li> <p><code>TEMPERATURE: float = 0.03</code> Controls randomness in the model's output.</p> </li> <li> <p><code>DETAILED_ERROR: bool = True</code> Enables or disables detailed error messages.</p> </li> <li> <p><code>SYSTEM_MESSAGE: SystemMessage = code_interpreter_system_message</code> Sets the default system message</p> </li> <li> <p><code>REQUEST_TIMEOUT: int = 3 * 60</code> API request timeout in seconds.</p> </li> <li> <p><code>MAX_ITERATIONS: int = 12</code> Maximum number of iterations for certain operations.</p> </li> <li> <p><code>MAX_RETRY: int = 3</code> Maximum number of API request retries.</p> </li> </ul>"},{"location":"settings/#production-settings","title":"Production Settings","text":"<ul> <li> <p><code>HISTORY_BACKEND: Optional[str] = None</code> Specifies the history backend to be used.</p> </li> <li> <p><code>REDIS_URL: str = \"redis://localhost:6379\"</code> URL for Redis server.</p> </li> <li> <p><code>POSTGRES_URL: str = \"postgresql://postgres:postgres@localhost:5432/postgres\"</code> URL for PostgreSQL server.</p> </li> </ul>"},{"location":"settings/#codebox","title":"CodeBox","text":"<ul> <li> <p><code>CODEBOX_API_KEY: Optional[str] = None</code> API key for the CodeBox service.</p> </li> <li> <p><code>CUSTOM_PACKAGES: list[str] = []</code> List of custom Python packages to be used.</p> </li> </ul>"},{"location":"settings/#deprecated","title":"Deprecated","text":"<ul> <li><code>VERBOSE: bool = DEBUG</code> This setting is deprecated and should not be used. It defaults to the value of <code>DEBUG</code>.</li> </ul>"},{"location":"streamlit_webapp/","title":"Using the Streamlit Webapp","text":"<p>The streamlit webapp allows interacting with the API through a GUI:</p> <pre><code>streamlit run frontend/app.py --browser.gatherUsageStats=False\n</code></pre> <p>This will launch the webapp where you can:</p> <ul> <li>Write prompts and see results immediately</li> <li>Upload files that get passed to the API</li> <li>Download any files produced by the API</li> <li>Switch between different models like GPT-3.5 Turbo</li> </ul> <p>So the webapp allows easily leveraging the API through a graphical interface.</p>"},{"location":"usage/","title":"Usage","text":"<p>To create a session and generate a response:</p> <pre><code>from codeinterpreterapi import CodeInterpreterSession, settings\n\n# set api key (or automatically loads from env vars)\nsettings.OPENAI_API_KEY = \"sk-***************\"\n\n# create a session\nwith CodeInterpreterSession() as session:\n    # generate a response based on user input\n    response = session.generate_response(\n        \"Plot the bitcoin chart of year 2023\"\n    )\n\n    # output the response\n    response.show()\n</code></pre>"},{"location":"user_request/","title":"UserRequest","text":"<p>The UserRequest class represents the user input to the agent.</p> <p>It contains:</p> <ul> <li><code>content</code>: text content of user message</li> <li><code>files</code>: list of File attachments</li> </ul> <p>Usage:</p> <pre><code>from codeinterpreterapi import UserRequest, File\n\nrequest = UserRequest(\n  content=\"Here is an image\",\n  files=[File.from_path(\"image.png\")]\n)\n</code></pre>"}]}